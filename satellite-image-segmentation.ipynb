{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport random\nimport datetime\nimport matplotlib.pyplot as plt\nfrom shapely.wkt import loads as wkt_loads\nimport tifffile as tiff\n\nfrom keras import backend as K\n# from sklearn.metrics import jaccard_similarity_score\n\nfrom shapely.geometry import MultiPolygon, Polygon\nimport shapely.wkt\nimport shapely.affinity\nfrom collections import defaultdict\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras import backend as keras\nimport gc\nimport warnings\nimport zipfile\nwarnings.filterwarnings(\"ignore\")\nfrom keras.models import load_model\nimport tensorflow as tf\nimport random as rn\nfrom tqdm import tqdm\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\nfrom tqdm import tqdm\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:48:50.854468Z","iopub.execute_input":"2022-06-25T07:48:50.855115Z","iopub.status.idle":"2022-06-25T07:48:57.521746Z","shell.execute_reply.started":"2022-06-25T07:48:50.855029Z","shell.execute_reply":"2022-06-25T07:48:57.520669Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"os.mkdir('/kaggle/data')\nos.mkdir('/kaggle/msk')\nos.mkdir('/kaggle/model_weights')\nos.mkdir('/kaggle/subm')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:49:02.686608Z","iopub.execute_input":"2022-06-25T07:49:02.687210Z","iopub.status.idle":"2022-06-25T07:49:02.694614Z","shell.execute_reply.started":"2022-06-25T07:49:02.687177Z","shell.execute_reply":"2022-06-25T07:49:02.693627Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"os.mkdir('/kaggle/x_tr_a')\nos.mkdir('/kaggle/x_tr_na')\nos.mkdir('/kaggle/y_tr_a')\nos.mkdir('/kaggle/y_tr_na')\n\nos.mkdir('/kaggle/x_val_a')\nos.mkdir('/kaggle/x_val_na')\nos.mkdir('/kaggle/y_val_a')\nos.mkdir('/kaggle/y_val_na')\n\nos.mkdir('/kaggle/x_test_a')\nos.mkdir('/kaggle/x_test_na')\nos.mkdir('/kaggle/y_test_a')\nos.mkdir('/kaggle/y_test_na')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:49:05.782282Z","iopub.execute_input":"2022-06-25T07:49:05.782611Z","iopub.status.idle":"2022-06-25T07:49:05.794266Z","shell.execute_reply.started":"2022-06-25T07:49:05.782583Z","shell.execute_reply":"2022-06-25T07:49:05.793345Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"## we are having 10 classes\nnum_cls = 10\n\nsize = 160\n\n#reduces and suppresses image noises\nsmooth = 1e-12\ninDir = '../input/dstl-satellite-imagery-feature-detection'\nTR = pd.read_csv(inDir + '/train_wkt_v4.csv.zip')\nGS = pd.read_csv(inDir + '/grid_sizes.csv.zip', names=['ImageId', 'Xmax', 'Ymin'], skiprows=1)\n\n#SF = pd.read_csv('/content/sample_submission.csv')\nGS = GS.rename( columns={'Unnamed: 0':'ImageId'}) #rename 'ImageId'","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:49:08.391268Z","iopub.execute_input":"2022-06-25T07:49:08.392242Z","iopub.status.idle":"2022-06-25T07:49:09.396869Z","shell.execute_reply.started":"2022-06-25T07:49:08.392201Z","shell.execute_reply":"2022-06-25T07:49:09.395943Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"## Adjusting the contrast of the image\n\ndef adjust_contrast(bands, lower_percent=2, higher_percent=98):\n    \"\"\"\n    to adjust the contrast of the image \n    bands is the image \n    \"\"\"\n    out = np.zeros_like(bands).astype(np.float32)\n    n = bands.shape[2]\n    for i in range(n):\n        a = 0  # min(band)\n        b = 1  # max(band)\n        c = np.percentile(bands[:, :, i], lower_percent)\n        d = np.percentile(bands[:, :, i], higher_percent)\n        t = a + (bands[:, :, i] - c) * (b - a) / (d - c)\n        t[t < a] = a\n        t[t > b] = b\n        out[:, :, i] = t\n\n    return out.astype(np.float32)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:49:11.709443Z","iopub.execute_input":"2022-06-25T07:49:11.710038Z","iopub.status.idle":"2022-06-25T07:49:11.718233Z","shell.execute_reply.started":"2022-06-25T07:49:11.710005Z","shell.execute_reply":"2022-06-25T07:49:11.716959Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"## converting the coordinates into raster(pixels)\ndef coordi_to_raster(coords, img_size, xmax, ymax):\n    \n    H, W = img_size\n    W1 = 1.0 * W * W / (W + 1)\n    H1 = 1.0 * H * H / (H + 1)\n    xf = W1 / xmax\n    yf = H1 / ymax\n    coords[:, 1] *= yf\n    coords[:, 0] *= xf\n    coords_int = np.round(coords).astype(np.int32)\n    return coords_int","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:49:13.924574Z","iopub.execute_input":"2022-06-25T07:49:13.925048Z","iopub.status.idle":"2022-06-25T07:49:13.931466Z","shell.execute_reply.started":"2022-06-25T07:49:13.925010Z","shell.execute_reply":"2022-06-25T07:49:13.930543Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"## creating the image masks with mutliploygon objects using exterior and interior coordinates of the given multiploygon\ndef convert_contours(polygonList, raster_img_size, xmax, ymax):\n    \n    perim_list = []\n    interior_list = []\n    if polygonList is None:\n        return None\n    for k in range(len(polygonList)):\n        poly = polygonList[k]\n        perim = np.array(list(poly.exterior.coords))\n        perim_c = coordi_to_raster(perim, raster_img_size, xmax, ymax)\n        perim_list.append(perim_c)\n        for pi in poly.interiors:\n            interior = np.array(list(pi.coords))\n            interior_c = coordi_to_raster(interior, raster_img_size, xmax, ymax)\n            interior_list.append(interior_c)\n    return perim_list, interior_list\n","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:49:15.844698Z","iopub.execute_input":"2022-06-25T07:49:15.845514Z","iopub.status.idle":"2022-06-25T07:49:15.853588Z","shell.execute_reply.started":"2022-06-25T07:49:15.845467Z","shell.execute_reply":"2022-06-25T07:49:15.852221Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# to generate the image masks using the image_size, image_id, class_type\ndef generate_mask_for_image_and_class(raster_size, image_id, class_type):\n\n    xmax, ymax = GS[GS.ImageId == image_id].iloc[0, 1:].astype(float)\n\n    df_image = TR[TR.ImageId == image_id]\n    multipoly_def = df_image[df_image.ClassType == class_type].MultipolygonWKT\n    polygonList = None\n    if len(multipoly_def) > 0:\n        assert len(multipoly_def) == 1\n        polygonList = wkt_loads(multipoly_def.values[0])\n    \n    contours = convert_contours(polygonList, raster_size, xmax, ymax)\n\n    img_mask = np.zeros(raster_size, np.uint8)\n    if contours is None:\n        return img_mask\n    perim_list, interior_list = contours\n    cv2.fillPoly(img_mask, perim_list, 1)\n    cv2.fillPoly(img_mask, interior_list, 0)\n\n    return img_mask","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:49:18.419890Z","iopub.execute_input":"2022-06-25T07:49:18.420474Z","iopub.status.idle":"2022-06-25T07:49:18.428339Z","shell.execute_reply.started":"2022-06-25T07:49:18.420439Z","shell.execute_reply":"2022-06-25T07:49:18.427330Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"## returns image pathces(crops) of given image and mask patch_size = 160*160\n    \ndef get_patches(img, msk, name1, name2, name3, name4, amt, aug=True):\n\n    \n\n    random.seed(42)\n    is2 = int(1.0 * size)\n\n    xm, ym = img.shape[0] - is2, img.shape[1] - is2\n\n    a, b , c, d = [], [], [], []\n\n    # thresholds for each class to get patches\n    tr = [0.4, 0.1, 0.1, 0.15, 0.3, 0.95, 0.1, 0.05, 0.001, 0.005]\n    \n    xyz = np.ceil(amt*0.10).astype(int)\n    amt1 = amt-xyz\n    amt2 = xyz\n\n   # to get augmented data\n    for i in range(amt1):\n\n        xc = random.randint(0, xm)\n        yc = random.randint(0, ym)\n\n        im = img[xc:xc + is2, yc:yc + is2]\n        ms = msk[xc:xc + is2, yc:yc + is2]\n\n     \n        for j in range(num_cls):\n            sm = np.sum(ms[:, :, j])\n\n            if 1.0 * sm / is2 ** 2 > tr[j]:\n               \n                #augmentation\n                if aug:\n                    \n                    # reversing\n                    if random.uniform(0, 1) > 0.5:\n                        im = im[::-1]\n                        ms = ms[::-1]\n\n                    #flipping \n                    if random.uniform(0, 1) > 0.5:\n                        im = im[:, ::-1]\n                        ms = ms[:, ::-1]\n                    rotation = np.random.randint(4) # 0, 1, 2, 3\n\n                    #transpose & rotation\n                    if random.uniform(0, 1) > 0.5:\n                       im = np.rot90(im.transpose((1,0,2)), k=rotation)\n                       ms = np.rot90(ms.transpose((1,0,2)), k=rotation)\n                    \n                    #rotation\n                    if random.uniform(0, 1) > 0.5:\n                      im = np.rot90(im, k=rotation)\n                      ms = np.rot90(ms, k=rotation)\n                    \n                    #shearing \n                    if random.uniform(0, 1) > 0.5:\n                       im = tf.keras.preprocessing.image.apply_affine_transform(im, shear=0)\n                       im = tf.keras.preprocessing.image.apply_affine_transform(im, shear=0)\n                                     \n                \n                im = im.astype(np.float16)\n                ms = ms.astype(np.float16)\n                \n                \n                np.save(\"/kaggle/{}/{}\".format(name1, i),im)  \n                np.save(\"/kaggle/{}/{}\".format(name2, i),ms)  \n               \n                a.append(\"/kaggle/{}/{}.npy\".format(name1, i))\n                b.append(\"/kaggle/{}/{}.npy\".format(name2, i))\n\n    # to get non-augmented data\n    for i in range(amt2):\n        xc = random.randint(0, xm)\n        yc = random.randint(0, ym)\n\n        im = img[xc:xc + is2, yc:yc + is2]\n        ms = msk[xc:xc + is2, yc:yc + is2]\n\n        im = im.astype(np.float16)\n        ms = ms.astype(np.float16)\n                                  \n        np.save(\"/kaggle/{}/{}\".format(name3, i),im)  \n        np.save(\"/kaggle/{}/{}\".format(name4, i),ms)  \n                \n        c.append(\"/kaggle/{}/{}.npy\".format(name3, i))\n        d.append(\"/kaggle/{}/{}.npy\".format(name4, i))\n\n    \n    print(len(a), len(b))\n    print(len(c), len(d))\n  \n    return a+c, b+d","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:49:20.524472Z","iopub.execute_input":"2022-06-25T07:49:20.525128Z","iopub.status.idle":"2022-06-25T07:49:20.546751Z","shell.execute_reply.started":"2022-06-25T07:49:20.525091Z","shell.execute_reply":"2022-06-25T07:49:20.545878Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class Dataloder(tf.keras.utils.Sequence):    \n    def __init__(self, dataset, batch_size=1, shuffle=False):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.indexes = np.arange(len(dataset))\n\n    def __getitem__(self, i):\n        \n        # collect batch data\n        start = i * self.batch_size\n        stop = (i + 1) * self.batch_size\n        data = []\n        for j in range(start, stop):\n            data.append(self.dataset[j])\n        \n        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n        \n        #print(len(batch))\n        return tuple(batch)\n    \n    def __len__(self):\n        return len(self.indexes) // self.batch_size\n\nclass Dataset:\n  \n    def __init__(self, images_dir, mask_dir):\n        \n        self.ids = images_dir\n        self.images_fps = images_dir\n        self.masks_fps  = mask_dir\n    \n    def __getitem__(self, i):\n        \n        # read data\n        image = np.load(self.images_fps[i]) \n        mask  = np.load(self.masks_fps[i])\n\n          \n        image = np.stack(image, axis=-1).astype('float')\n        mask = np.stack(mask, axis=-1).astype('float')\n\n        #image = np.transpose(image, (1,0,2)) \n        #mask = np.transpose(mask, (1,0,2)) \n    \n        image = np.transpose(image, (0,2,1)) \n        mask = np.transpose(mask, (0,2,1)) \n  \n        return image, mask\n      \n    def __len__(self):\n        return len(self.ids)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:49:24.570609Z","iopub.execute_input":"2022-06-25T07:49:24.571244Z","iopub.status.idle":"2022-06-25T07:49:24.583318Z","shell.execute_reply.started":"2022-06-25T07:49:24.571207Z","shell.execute_reply":"2022-06-25T07:49:24.582191Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"## rgb image detection using M band\ndef M(image_id):\n    zip_path = '../input/dstl-satellite-imagery-feature-detection/sixteen_band.zip'\n    tgtImg = '{}_M.tif'.format(image_id)\n    with zipfile.ZipFile(zip_path) as myzip:\n        files_in_zip = myzip.namelist()\n        for fname in files_in_zip:\n            if fname.endswith(tgtImg):\n                with myzip.open(fname) as myfile:\n                    img = tiff.imread(myfile)\n                    img = np.rollaxis(img, 0, 3)\n                    return img\n                \n                \n\nprint (\"combining all the images\")\ns = 835\n\nX = np.zeros((5 * s, 5 * s, 8))\nY = np.zeros((5 * s, 5 * s, num_cls))  \n\nids = sorted(set(TR.ImageId))\nprint (len(ids))\n\nfor i in range(5):\n    for j in range(5):\n        id = ids[5 * i + j]\n\n        rgb_img = M(id)\n        img = adjust_contrast(rgb_img).copy()\n        \n        \n        print (img.shape, id)\n        X[s * i:s * i + s, s * j:s * j + s, :] = img[:s, :s, :]\n        for z in range(num_cls):\n            Y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n                (img.shape[0], img.shape[1]), id, z + 1)[:s, :s]\n\nnp.save('/kaggle/data/X', X)\nnp.save('/kaggle/data/Y', Y)\nprint(X.shape)\nprint(Y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:49:28.029156Z","iopub.execute_input":"2022-06-25T07:49:28.029494Z","iopub.status.idle":"2022-06-25T07:49:53.709506Z","shell.execute_reply.started":"2022-06-25T07:49:28.029467Z","shell.execute_reply":"2022-06-25T07:49:53.708408Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Splitting the dataset into training, validation and test dataset","metadata":{}},{"cell_type":"code","source":"#img, msk, name1, name2, name3, name4, amt, aug=True\n#training the dataset\nx_train, y_train = get_patches(X, Y, 'x_tr_a', 'y_tr_a', 'x_tr_na', 'y_tr_na', 20000, aug=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:50:03.157480Z","iopub.execute_input":"2022-06-25T07:50:03.157817Z","iopub.status.idle":"2022-06-25T07:51:55.226971Z","shell.execute_reply.started":"2022-06-25T07:50:03.157788Z","shell.execute_reply":"2022-06-25T07:51:55.225940Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#validation dataset\nx_val, y_val = get_patches(X, Y, 'x_val_a', 'y_val_a', 'x_val_na', 'y_val_na', 4000, aug=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:51:59.244198Z","iopub.execute_input":"2022-06-25T07:51:59.244540Z","iopub.status.idle":"2022-06-25T07:52:24.941999Z","shell.execute_reply.started":"2022-06-25T07:51:59.244512Z","shell.execute_reply":"2022-06-25T07:52:24.941031Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#test dataset\nx_test, y_test = get_patches(X, Y, 'x_test_a', 'y_test_na', 'x_test_a', 'y_test_na', 4000, aug=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:52:42.682397Z","iopub.execute_input":"2022-06-25T07:52:42.682751Z","iopub.status.idle":"2022-06-25T07:53:04.813495Z","shell.execute_reply.started":"2022-06-25T07:52:42.682722Z","shell.execute_reply":"2022-06-25T07:53:04.805356Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(x_train, y_train)\ntrain_dataloader = Dataloder(train_dataset, batch_size=8)\nval_dataset = Dataset(x_val, y_val)\nval_dataloader = Dataloder(val_dataset, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:53:09.264717Z","iopub.execute_input":"2022-06-25T07:53:09.265080Z","iopub.status.idle":"2022-06-25T07:53:09.270485Z","shell.execute_reply.started":"2022-06-25T07:53:09.265052Z","shell.execute_reply":"2022-06-25T07:53:09.269421Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_dataloader[0][0].shape","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:53:12.271576Z","iopub.execute_input":"2022-06-25T07:53:12.271941Z","iopub.status.idle":"2022-06-25T07:53:13.714940Z","shell.execute_reply.started":"2022-06-25T07:53:12.271893Z","shell.execute_reply":"2022-06-25T07:53:13.713938Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"## calculating the jaccard coefficient\ndef jaccard_coef(y_true, y_pred):\n    \n    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n    total = K.sum(y_true + y_pred, axis=[0, -1, -2])\n    union = total - intersection\n\n    jac = (intersection + smooth) / (union+ smooth)\n\n    return K.mean(jac)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:53:18.058631Z","iopub.execute_input":"2022-06-25T07:53:18.059080Z","iopub.status.idle":"2022-06-25T07:53:18.071087Z","shell.execute_reply.started":"2022-06-25T07:53:18.059041Z","shell.execute_reply":"2022-06-25T07:53:18.069937Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"##fixing numpy RS\nnp.random.seed(42)\n\n##fixing tensorflow RS\ntf.random.set_seed(32)\n\n##python RS\nrn.seed(12)\n\ndef UNet():\n    \n    tf.random.set_seed(32)\n    classes= 10\n    img_input = Input(shape=(size, size, 8))\n    x = img_input\n\n    # Making the Encoder \n    \n    x = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 23))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(64, (3, 3), activation='relu', padding='same',  kernel_initializer = tf.keras.initializers.he_normal(seed= 43))(x)\n   # x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n    x = Dropout(0.25)(x)\n    \n    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 32))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 41))(x)\n   # x = BatchNormalization()(x)\n    x = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 33))(x)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n    x = Dropout(0.5)(x)\n\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 35))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 54))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 39))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    \n    #Making the Decoder\n    \n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(128, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 45))(x)\n   # x = BatchNormalization()(x)\n    x = Conv2D(128, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 41))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(128, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 49))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.25)(x)\n      \n    x = UpSampling2D(size=(2, 2))(x)\n    x = Conv2D(64, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 18))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(64, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 21))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(classes, kernel_size=3, activation='relu', padding='same', kernel_initializer = tf.keras.initializers.he_normal(seed= 16))(x)\n    x = Dropout(0.25)(x)\n  \n    x = Activation(\"softmax\")(x)\n    \n    model = Model(img_input, x)\n  \n    model.compile(optimizer='Adam',loss='binary_crossentropy', metrics=[jaccard_coef])\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:53:21.362030Z","iopub.execute_input":"2022-06-25T07:53:21.362714Z","iopub.status.idle":"2022-06-25T07:53:21.386210Z","shell.execute_reply.started":"2022-06-25T07:53:21.362682Z","shell.execute_reply":"2022-06-25T07:53:21.385210Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"##changing the learning rates\ndef changeLearningRate(epoch):\n\n    #lr=0.001\n    lr=0.0001\n    if epoch > 10 and epoch <=20:\n      lr*=0.1\n    elif epoch > 20 and epoch <=30:\n      lr*=0.01\n    elif epoch > 30 and epoch <=40:\n      lr*=0.001\n    elif epoch > 40 and epoch <=50:  \n      lr*=0.0001\n    elif epoch > 50 and epoch <=60:  \n      lr*=0.0001  \n    elif epoch > 60:\n      lr*=0.0001\n\n    return lr","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:53:25.403800Z","iopub.execute_input":"2022-06-25T07:53:25.404374Z","iopub.status.idle":"2022-06-25T07:53:25.410717Z","shell.execute_reply.started":"2022-06-25T07:53:25.404340Z","shell.execute_reply":"2022-06-25T07:53:25.409676Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"## to stop the nueral network using callback functions\n\nACCURACY_THRESHOLD=0.502\n\nclass myCallback(tf.keras.callbacks.Callback): \n    \n    def on_epoch_end(self, epoch, logs={}): \n        if (logs.get('val_jaccard_coef') > ACCURACY_THRESHOLD) and (logs.get('jaccard_coef') > ACCURACY_THRESHOLD):   \n          print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n          self.model.stop_training = True\n\nstop = myCallback()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:53:27.966669Z","iopub.execute_input":"2022-06-25T07:53:27.967028Z","iopub.status.idle":"2022-06-25T07:53:27.973244Z","shell.execute_reply.started":"2022-06-25T07:53:27.966999Z","shell.execute_reply":"2022-06-25T07:53:27.971959Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"filepath=\"/kaggle/model_weights/weights-{epoch:02d}-{val_jaccard_coef:.4f}.hdf5\"\n\ncheckpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss',  verbose=1, save_best_only=True, mode='auto')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:53:30.123507Z","iopub.execute_input":"2022-06-25T07:53:30.123929Z","iopub.status.idle":"2022-06-25T07:53:30.130299Z","shell.execute_reply.started":"2022-06-25T07:53:30.123879Z","shell.execute_reply":"2022-06-25T07:53:30.129347Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"## to reduce the learning rate when the metric has stopped improving\n\nrlrop = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose = 1, min_delta = 0.0001)\nlrschedule = LearningRateScheduler(changeLearningRate, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:53:33.119743Z","iopub.execute_input":"2022-06-25T07:53:33.120504Z","iopub.status.idle":"2022-06-25T07:53:33.126127Z","shell.execute_reply.started":"2022-06-25T07:53:33.120462Z","shell.execute_reply":"2022-06-25T07:53:33.124790Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model = UNet()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:53:35.321343Z","iopub.execute_input":"2022-06-25T07:53:35.321689Z","iopub.status.idle":"2022-06-25T07:53:38.847717Z","shell.execute_reply.started":"2022-06-25T07:53:35.321659Z","shell.execute_reply":"2022-06-25T07:53:38.846744Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"## summary of the U-NET model\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T07:53:56.005546Z","iopub.execute_input":"2022-06-25T07:53:56.005890Z","iopub.status.idle":"2022-06-25T07:53:56.017008Z","shell.execute_reply.started":"2022-06-25T07:53:56.005862Z","shell.execute_reply":"2022-06-25T07:53:56.015852Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"##fitting the model\n\nmodel_fitting = model.fit(train_dataloader, \n                              steps_per_epoch=len(train_dataloader),\n                              epochs=15,\n                              validation_data=val_dataloader, \n                              callbacks=checkpoint\n                              )","metadata":{"execution":{"iopub.status.busy":"2022-06-25T08:42:00.424153Z","iopub.execute_input":"2022-06-25T08:42:00.424547Z","iopub.status.idle":"2022-06-25T09:10:46.188736Z","shell.execute_reply.started":"2022-06-25T08:42:00.424516Z","shell.execute_reply":"2022-06-25T09:10:46.185805Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"test_dataset = Dataset(x_test, y_test)\ntest_dataloader = Dataloder(test_dataset, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:11:33.867566Z","iopub.execute_input":"2022-06-25T09:11:33.867966Z","iopub.status.idle":"2022-06-25T09:11:33.880798Z","shell.execute_reply.started":"2022-06-25T09:11:33.867931Z","shell.execute_reply":"2022-06-25T09:11:33.879737Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"model = UNet()\nmodel.load_weights(\"/kaggle/model_weights/weights-20-0.2539.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:12:08.778038Z","iopub.execute_input":"2022-06-25T09:12:08.778980Z","iopub.status.idle":"2022-06-25T09:12:10.617085Z","shell.execute_reply.started":"2022-06-25T09:12:08.778933Z","shell.execute_reply":"2022-06-25T09:12:10.615698Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"Score= []\nfor i in tqdm(range(len(test_dataloader))):\n   pred_msk = model.predict(test_dataloader[i][0])\n   score = jaccard_coef(test_dataloader[i][1], pred_msk)\n   Score.append(score)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:12:46.384404Z","iopub.execute_input":"2022-06-25T09:12:46.384794Z","iopub.status.idle":"2022-06-25T09:14:33.694216Z","shell.execute_reply.started":"2022-06-25T09:12:46.384756Z","shell.execute_reply":"2022-06-25T09:14:33.693106Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"score = sum(Score)/len(test_dataloader)\nprint(\"The score obtained on the test data is: \", score.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:14:58.240459Z","iopub.execute_input":"2022-06-25T09:14:58.240851Z","iopub.status.idle":"2022-06-25T09:14:58.299625Z","shell.execute_reply.started":"2022-06-25T09:14:58.240820Z","shell.execute_reply":"2022-06-25T09:14:58.298594Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"Performing Error Analysis","metadata":{}},{"cell_type":"code","source":"model = UNet()\nmodel.load_weights(\"/kaggle/model_weights/weights-20-0.2539.hdf5\")","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:20:49.988066Z","iopub.execute_input":"2022-06-25T09:20:49.988476Z","iopub.status.idle":"2022-06-25T09:20:50.278658Z","shell.execute_reply.started":"2022-06-25T09:20:49.988440Z","shell.execute_reply":"2022-06-25T09:20:50.276417Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"## total x and y values\ntotal_x = x_train + x_val + x_test\ntotal_y = y_train + y_val+ y_test","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:21:46.602454Z","iopub.execute_input":"2022-06-25T09:21:46.602844Z","iopub.status.idle":"2022-06-25T09:21:46.609596Z","shell.execute_reply.started":"2022-06-25T09:21:46.602792Z","shell.execute_reply":"2022-06-25T09:21:46.608587Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"total_dataset = Dataset(total_x, total_y)\ntotal_dataloader = Dataloder(total_dataset, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:22:04.602617Z","iopub.execute_input":"2022-06-25T09:22:04.603225Z","iopub.status.idle":"2022-06-25T09:22:04.609035Z","shell.execute_reply.started":"2022-06-25T09:22:04.603187Z","shell.execute_reply":"2022-06-25T09:22:04.607857Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"## to compute the similarity between two objects using jaccard coefficient\n\nScore= []\nvery_low_jaccard=[]\nmedium_jaccard= []\nvery_high_jaccard= []\n\nfor i in tqdm(range(len(total_dataloader))):\n\n   pred_msk = model.predict(total_dataloader[i][0])\n   score = jaccard_coef(total_dataloader[i][1], pred_msk)\n   \n   if score>0 and score <=0.20:\n      very_low_jaccard.append(i)\n\n   elif score>0.20 and score <=0.70:\n      medium_jaccard.append(i)\n   \n   elif score>0.70 and score <=1:\n      very_high_jaccard.append(i)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:23:20.053163Z","iopub.execute_input":"2022-06-25T09:23:20.053562Z","iopub.status.idle":"2022-06-25T09:36:14.677132Z","shell.execute_reply.started":"2022-06-25T09:23:20.053529Z","shell.execute_reply":"2022-06-25T09:36:14.674921Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"Very_low_jaccard_x = []\nMedium_jaccard_x = []\nVery_high_jaccard_x = []\n\nVery_low_jaccard_y = []\nMedium_jaccard_y = []\nVery_high_jaccard_y = []\n\nfor i in very_low_jaccard:\n   Very_low_jaccard_x.append(total_x[i])\nfor i in medium_jaccard:\n   Medium_jaccard_x.append(total_x[i])\nfor i in very_high_jaccard:\n   Very_high_jaccard_x.append(total_x[i])      \n\nfor i in very_low_jaccard:\n   Very_low_jaccard_y.append(total_y[i])\nfor i in medium_jaccard:\n   Medium_jaccard_y.append(total_y[i])\nfor i in very_high_jaccard:\n   Very_high_jaccard_y.append(total_y[i])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:36:54.454452Z","iopub.execute_input":"2022-06-25T09:36:54.454807Z","iopub.status.idle":"2022-06-25T09:36:54.469987Z","shell.execute_reply.started":"2022-06-25T09:36:54.454775Z","shell.execute_reply":"2022-06-25T09:36:54.468964Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"np.save(\"vljx\", Very_low_jaccard_x)\nnp.save(\"vljy\", Very_low_jaccard_y)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:37:08.511215Z","iopub.execute_input":"2022-06-25T09:37:08.511564Z","iopub.status.idle":"2022-06-25T09:37:08.529132Z","shell.execute_reply.started":"2022-06-25T09:37:08.511535Z","shell.execute_reply":"2022-06-25T09:37:08.528251Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"vljx = np.load(\"vljx.npy\")\nvljy = np.load(\"vljy.npy\")","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:37:17.882503Z","iopub.execute_input":"2022-06-25T09:37:17.882848Z","iopub.status.idle":"2022-06-25T09:37:17.891673Z","shell.execute_reply.started":"2022-06-25T09:37:17.882816Z","shell.execute_reply":"2022-06-25T09:37:17.890581Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"## converting a mask image into polygons\n    \ndef mask_to_polygons(mask, epsilon=5, min_area=1.):\n    \n    ##to detect objects in image\n    contours, hierarchy = cv2.findContours(((mask == 1) * 255).astype(np.uint8), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_TC89_KCOS)\n    approx_contours = [cv2.approxPolyDP(cnt, epsilon, True)\n                       for cnt in contours]\n    if not contours:\n        return MultiPolygon()\n\n    cnt_children = defaultdict(list)\n    child_contours = set()\n    assert hierarchy.shape[0] == 1\n\n    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n        if parent_idx != -1:\n            child_contours.add(idx)\n            cnt_children[parent_idx].append(approx_contours[idx])\n\n    # creating actual polygons filtering it by area \n    all_polygons = []\n    for idx, cnt in enumerate(approx_contours):\n        if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n            assert cnt.shape[1] == 1\n            poly = Polygon(\n                shell=cnt[:, 0, :],\n                holes=[c[:, 0, :] for c in cnt_children.get(idx, [])\n                       if cv2.contourArea(c) >= min_area])\n            all_polygons.append(poly)\n            \n    # approximating polygons might have created invalid ones, fix them\n    \n    all_polygons = MultiPolygon(all_polygons)\n    if not all_polygons.is_valid:\n        all_polygons = all_polygons.buffer(0)\n        # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n        # need to keep it a Multi throughout\n        if all_polygons.type == 'Polygon':\n            all_polygons = MultiPolygon([all_polygons])\n    return all_polygons","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:40:19.154178Z","iopub.execute_input":"2022-06-25T09:40:19.154555Z","iopub.status.idle":"2022-06-25T09:40:19.169062Z","shell.execute_reply.started":"2022-06-25T09:40:19.154523Z","shell.execute_reply":"2022-06-25T09:40:19.168052Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"DF  = pd.DataFrame(columns=[\"image\", \"class\", \"poly\"])\n\nfor i in range(25):\n   abcd = np.load(vljy[i])\n   image, cl , ploy = [],[],[]\n  \n   for j in range(10):\n     ab = mask_to_polygons(abcd[:,:,j], epsilon=1)\n     image.append(i+1)\n     cl.append(j+1)\n     ploy.append(len(ab))\n     df = pd.DataFrame(list(zip(image, cl, ploy)), columns = ['image', 'class', 'poly'])\n\n   DF = pd.concat([DF,df], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:40:34.774491Z","iopub.execute_input":"2022-06-25T09:40:34.774835Z","iopub.status.idle":"2022-06-25T09:40:35.406674Z","shell.execute_reply.started":"2022-06-25T09:40:34.774807Z","shell.execute_reply":"2022-06-25T09:40:35.405732Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"objects_per_image = DF.pivot(index='class', columns='image', values='poly')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:40:47.908733Z","iopub.execute_input":"2022-06-25T09:40:47.909680Z","iopub.status.idle":"2022-06-25T09:40:47.951814Z","shell.execute_reply.started":"2022-06-25T09:40:47.909639Z","shell.execute_reply":"2022-06-25T09:40:47.950939Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"OBSERVATIONS","metadata":{}},{"cell_type":"code","source":"print(\"minimum value in an image\",np.amin(np.load(vljx[0])))\nprint(\"maximum value in an image\",np.amax(np.load(vljx[0])))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:41:17.248712Z","iopub.execute_input":"2022-06-25T09:41:17.249302Z","iopub.status.idle":"2022-06-25T09:41:17.283344Z","shell.execute_reply.started":"2022-06-25T09:41:17.249258Z","shell.execute_reply":"2022-06-25T09:41:17.282342Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"threshold = 0.4\nSum = []\n\nfor i in tqdm(range(25)):\n   a = np.load(vljx[i])\n   im= []\n   for j in range(8):\n     im.append(np.count_nonzero(np.less(a[:,:,j], threshold))) \n   x = sum(im)\n   Sum.append(x)  \npercentage = (sum(Sum)/(160*160*8*25))*100","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:41:28.097017Z","iopub.execute_input":"2022-06-25T09:41:28.097506Z","iopub.status.idle":"2022-06-25T09:41:28.270640Z","shell.execute_reply.started":"2022-06-25T09:41:28.097463Z","shell.execute_reply":"2022-06-25T09:41:28.269597Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"## plotting the image\ndef plot_image(image_id):\n\n  m = np.load(vljx[image_id])\n  m = adjust_contrast(m)\n  img = np.zeros((m.shape[0],m.shape[1],3))\n  img[:,:,0] = m[:,:,4] #red\n  img[:,:,1] = m[:,:,2] #green\n  img[:,:,2] = m[:,:,1] #blue\n  #plt.figure(figsize=(7,7))\n  plt.imshow(img, interpolation='nearest')\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:41:49.504311Z","iopub.execute_input":"2022-06-25T09:41:49.504677Z","iopub.status.idle":"2022-06-25T09:41:49.512736Z","shell.execute_reply.started":"2022-06-25T09:41:49.504645Z","shell.execute_reply":"2022-06-25T09:41:49.511548Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def plot_mask(mask_id):\n  m = np.load(vljy[i])\n  m = adjust_contrast(m)\n  img = np.zeros((m.shape[0],m.shape[1],3)) \n  img[:,:,0] = m[:,:,4] #red\n  img[:,:,1] = m[:,:,2] #green\n  img[:,:,2] = m[:,:,1] #blue\n  #plt.figure(figsize=(7,7))\n  plt.imshow(img, interpolation='nearest')\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:41:57.568696Z","iopub.execute_input":"2022-06-25T09:41:57.569070Z","iopub.status.idle":"2022-06-25T09:41:57.578862Z","shell.execute_reply.started":"2022-06-25T09:41:57.569037Z","shell.execute_reply":"2022-06-25T09:41:57.577953Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"for i in range(3):\n   plot_image(i)\n   plot_mask(i)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T09:42:04.872107Z","iopub.execute_input":"2022-06-25T09:42:04.872474Z","iopub.status.idle":"2022-06-25T09:42:06.228769Z","shell.execute_reply.started":"2022-06-25T09:42:04.872442Z","shell.execute_reply":"2022-06-25T09:42:06.227830Z"},"trusted":true},"execution_count":47,"outputs":[]}]}